{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d76fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from squeezer.criterion import distill_loss\n",
    "from squeezer.distiller import Distiller\n",
    "from squeezer.policy import AbstractDistillationPolicy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe5093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff5e417b370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0xDEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9008179",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcffb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, n_epochs: int = 200):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        for i, (data, labels) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b7f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for data, labels in loader:\n",
    "        outputs = model(data).argmax(-1)\n",
    "        preds.append(outputs)\n",
    "        targets.append(labels)\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    print(classification_report(targets, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3466b95",
   "metadata": {},
   "source": [
    "# Models\n",
    "Объявляем модель-учитель побольше и модель-ученик поменьше.  \n",
    "Тип возвращаемого значения должен наследоваться от класса `ModelOutput` (или быть им)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a2c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = self.network(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e165954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = self.network(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d0964",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ee7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(num_features: int = 64, num_classes: int = 4,\n",
    "                batch_size: int = 64, train_size: float = 0.75):\n",
    "    x, y = make_classification(\n",
    "        1000, num_features,\n",
    "        n_classes=num_classes,\n",
    "        n_informative=int(num_features * 0.9),\n",
    "        n_clusters_per_class=2,\n",
    "        class_sep=4.0,\n",
    "        random_state=0xDEAD\n",
    "    )\n",
    "    dataset = TensorDataset(\n",
    "        torch.from_numpy(x).float(),\n",
    "        torch.from_numpy(y).long()\n",
    "    )\n",
    "    dataset_length = len(x)\n",
    "    train_size = int(dataset_length * train_size)\n",
    "    val_size = dataset_length - train_size\n",
    "    train, val = random_split(dataset, [train_size, val_size])\n",
    "    return DataLoader(train, batch_size=batch_size), DataLoader(val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ef77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 128\n",
    "num_classes = 5\n",
    "\n",
    "train_loader, val_loader = get_loaders(num_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e2ad8",
   "metadata": {},
   "source": [
    "# Train Teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa59313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 52.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        57\n",
      "           1       1.00      1.00      1.00        55\n",
      "           2       0.98      1.00      0.99        45\n",
      "           3       1.00      0.98      0.99        47\n",
      "           4       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           0.99       250\n",
      "   macro avg       0.99      0.99      0.99       250\n",
      "weighted avg       0.99      0.99      0.99       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "teacher = Teacher(num_features, num_classes, hidden_size=128)\n",
    "\n",
    "train(teacher, train_loader, n_epochs=n_epochs)\n",
    "evaluate(teacher, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83c2b7",
   "metadata": {},
   "source": [
    "# Train Student model without distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb16df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 123.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97        57\n",
      "           1       0.96      0.96      0.96        55\n",
      "           2       0.93      0.96      0.95        45\n",
      "           3       0.98      0.94      0.96        47\n",
      "           4       0.98      0.98      0.98        46\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "student = Student(num_features, num_classes)\n",
    "train(student, train_loader, n_epochs=n_epochs)\n",
    "evaluate(student, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc17257",
   "metadata": {},
   "source": [
    "# Distiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf399ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDistiller(Distiller):\n",
    "    def teacher_forward(self, batch):\n",
    "        return self.teacher(batch[0])\n",
    "    \n",
    "    def student_forward(self, batch):\n",
    "        return self.student(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa8184",
   "metadata": {},
   "source": [
    "# Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9319c9",
   "metadata": {},
   "source": [
    "## Basic distillation policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "498be39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class BasicDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def __init__(self, temperature: float = 1.0, alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, teacher_output, student_output, batch, epoch: int) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        loss_kld, loss_ce, overall = distill_loss(\n",
    "            teacher_logits=teacher_output,\n",
    "            student_logits=student_output,\n",
    "            labels=batch[1],\n",
    "            temperature=self.temperature,\n",
    "            alpha=self.alpha\n",
    "        )\n",
    "        loss_dict = {\n",
    "            'kld': loss_kld.item(),\n",
    "            'cross_entropy': loss_ce.item(),\n",
    "            'overall': overall.item(),\n",
    "        }\n",
    "        return overall, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf99fff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: kld=0.53002   cross_entropy=0.43194   overall=0.48098\n",
      "Epoch 1: kld=0.44321   cross_entropy=0.35951   overall=0.40136\n",
      "Epoch 2: kld=0.36695   cross_entropy=0.29611   overall=0.33153\n",
      "Epoch 3: kld=0.30198   cross_entropy=0.24205   overall=0.27202\n",
      "Epoch 4: kld=0.24861   cross_entropy=0.19781   overall=0.22321\n",
      "Epoch 5: kld=0.20615   cross_entropy=0.16302   overall=0.18458\n",
      "Epoch 6: kld=0.17253   cross_entropy=0.13570   overall=0.15412\n",
      "Epoch 7: kld=0.14562   cross_entropy=0.11391   overall=0.12976\n",
      "Epoch 8: kld=0.12375   cross_entropy=0.09623   overall=0.10999\n",
      "Epoch 9: kld=0.10569   cross_entropy=0.08162   overall=0.09366\n",
      "Epoch 10: kld=0.09064   cross_entropy=0.06940   overall=0.08002\n",
      "Epoch 11: kld=0.07801   cross_entropy=0.05916   overall=0.06858\n",
      "Epoch 12: kld=0.06741   cross_entropy=0.05057   overall=0.05899\n",
      "Epoch 13: kld=0.05846   cross_entropy=0.04336   overall=0.05091\n",
      "Epoch 14: kld=0.05089   cross_entropy=0.03728   overall=0.04408\n",
      "Epoch 15: kld=0.04443   cross_entropy=0.03212   overall=0.03828\n",
      "Epoch 16: kld=0.03891   cross_entropy=0.02773   overall=0.03332\n",
      "Epoch 17: kld=0.03416   cross_entropy=0.02397   overall=0.02907\n",
      "Epoch 18: kld=0.03006   cross_entropy=0.02075   overall=0.02540\n",
      "Epoch 19: kld=0.02651   cross_entropy=0.01797   overall=0.02224\n",
      "Epoch 20: kld=0.02343   cross_entropy=0.01557   overall=0.01950\n",
      "Epoch 21: kld=0.02076   cross_entropy=0.01351   overall=0.01713\n",
      "Epoch 22: kld=0.01844   cross_entropy=0.01173   overall=0.01508\n",
      "Epoch 23: kld=0.01643   cross_entropy=0.01020   overall=0.01332\n",
      "Epoch 24: kld=0.01469   cross_entropy=0.00890   overall=0.01180\n",
      "Epoch 25: kld=0.01319   cross_entropy=0.00779   overall=0.01049\n",
      "Epoch 26: kld=0.01190   cross_entropy=0.00685   overall=0.00937\n",
      "Epoch 27: kld=0.01079   cross_entropy=0.00605   overall=0.00842\n",
      "Epoch 28: kld=0.00982   cross_entropy=0.00538   overall=0.00760\n",
      "Epoch 29: kld=0.00899   cross_entropy=0.00481   overall=0.00690\n",
      "Epoch 30: kld=0.00827   cross_entropy=0.00432   overall=0.00630\n",
      "Epoch 31: kld=0.00764   cross_entropy=0.00391   overall=0.00578\n",
      "Epoch 32: kld=0.00710   cross_entropy=0.00355   overall=0.00533\n",
      "Epoch 33: kld=0.00662   cross_entropy=0.00325   overall=0.00493\n",
      "Epoch 34: kld=0.00620   cross_entropy=0.00299   overall=0.00459\n",
      "Epoch 35: kld=0.00583   cross_entropy=0.00276   overall=0.00429\n",
      "Epoch 36: kld=0.00550   cross_entropy=0.00256   overall=0.00403\n",
      "Epoch 37: kld=0.00521   cross_entropy=0.00239   overall=0.00380\n",
      "Epoch 38: kld=0.00495   cross_entropy=0.00223   overall=0.00359\n",
      "Epoch 39: kld=0.00472   cross_entropy=0.00210   overall=0.00341\n",
      "Epoch 40: kld=0.00451   cross_entropy=0.00198   overall=0.00324\n",
      "Epoch 41: kld=0.00432   cross_entropy=0.00188   overall=0.00310\n",
      "Epoch 42: kld=0.00415   cross_entropy=0.00178   overall=0.00297\n",
      "Epoch 43: kld=0.00399   cross_entropy=0.00170   overall=0.00285\n",
      "Epoch 44: kld=0.00385   cross_entropy=0.00162   overall=0.00274\n",
      "Epoch 45: kld=0.00372   cross_entropy=0.00155   overall=0.00264\n",
      "Epoch 46: kld=0.00360   cross_entropy=0.00149   overall=0.00255\n",
      "Epoch 47: kld=0.00349   cross_entropy=0.00143   overall=0.00246\n",
      "Epoch 48: kld=0.00339   cross_entropy=0.00138   overall=0.00239\n",
      "Epoch 49: kld=0.00329   cross_entropy=0.00134   overall=0.00231\n",
      "Epoch 50: kld=0.00321   cross_entropy=0.00129   overall=0.00225\n",
      "Epoch 51: kld=0.00312   cross_entropy=0.00125   overall=0.00219\n",
      "Epoch 52: kld=0.00305   cross_entropy=0.00121   overall=0.00213\n",
      "Epoch 53: kld=0.00297   cross_entropy=0.00118   overall=0.00208\n",
      "Epoch 54: kld=0.00290   cross_entropy=0.00114   overall=0.00202\n",
      "Epoch 55: kld=0.00284   cross_entropy=0.00111   overall=0.00198\n",
      "Epoch 56: kld=0.00278   cross_entropy=0.00108   overall=0.00193\n",
      "Epoch 57: kld=0.00272   cross_entropy=0.00106   overall=0.00189\n",
      "Epoch 58: kld=0.00266   cross_entropy=0.00103   overall=0.00185\n",
      "Epoch 59: kld=0.00261   cross_entropy=0.00101   overall=0.00181\n",
      "Epoch 60: kld=0.00256   cross_entropy=0.00098   overall=0.00177\n",
      "Epoch 61: kld=0.00251   cross_entropy=0.00096   overall=0.00174\n",
      "Epoch 62: kld=0.00246   cross_entropy=0.00094   overall=0.00170\n",
      "Epoch 63: kld=0.00242   cross_entropy=0.00092   overall=0.00167\n",
      "Epoch 64: kld=0.00237   cross_entropy=0.00090   overall=0.00164\n",
      "Epoch 65: kld=0.00233   cross_entropy=0.00088   overall=0.00161\n",
      "Epoch 66: kld=0.00229   cross_entropy=0.00086   overall=0.00158\n",
      "Epoch 67: kld=0.00225   cross_entropy=0.00085   overall=0.00155\n",
      "Epoch 68: kld=0.00221   cross_entropy=0.00083   overall=0.00152\n",
      "Epoch 69: kld=0.00217   cross_entropy=0.00081   overall=0.00149\n",
      "Epoch 70: kld=0.00214   cross_entropy=0.00080   overall=0.00147\n",
      "Epoch 71: kld=0.00210   cross_entropy=0.00078   overall=0.00144\n",
      "Epoch 72: kld=0.00206   cross_entropy=0.00076   overall=0.00141\n",
      "Epoch 73: kld=0.00203   cross_entropy=0.00075   overall=0.00139\n",
      "Epoch 74: kld=0.00200   cross_entropy=0.00073   overall=0.00137\n",
      "Epoch 75: kld=0.00196   cross_entropy=0.00072   overall=0.00134\n",
      "Epoch 76: kld=0.00193   cross_entropy=0.00071   overall=0.00132\n",
      "Epoch 77: kld=0.00190   cross_entropy=0.00069   overall=0.00130\n",
      "Epoch 78: kld=0.00187   cross_entropy=0.00068   overall=0.00127\n",
      "Epoch 79: kld=0.00184   cross_entropy=0.00067   overall=0.00125\n",
      "Epoch 80: kld=0.00181   cross_entropy=0.00065   overall=0.00123\n",
      "Epoch 81: kld=0.00178   cross_entropy=0.00064   overall=0.00121\n",
      "Epoch 82: kld=0.00175   cross_entropy=0.00063   overall=0.00119\n",
      "Epoch 83: kld=0.00172   cross_entropy=0.00062   overall=0.00117\n",
      "Epoch 84: kld=0.00169   cross_entropy=0.00061   overall=0.00115\n",
      "Epoch 85: kld=0.00167   cross_entropy=0.00059   overall=0.00113\n",
      "Epoch 86: kld=0.00164   cross_entropy=0.00058   overall=0.00111\n",
      "Epoch 87: kld=0.00161   cross_entropy=0.00057   overall=0.00109\n",
      "Epoch 88: kld=0.00159   cross_entropy=0.00056   overall=0.00108\n",
      "Epoch 89: kld=0.00156   cross_entropy=0.00055   overall=0.00106\n",
      "Epoch 90: kld=0.00154   cross_entropy=0.00054   overall=0.00104\n",
      "Epoch 91: kld=0.00152   cross_entropy=0.00053   overall=0.00102\n",
      "Epoch 92: kld=0.00149   cross_entropy=0.00052   overall=0.00101\n",
      "Epoch 93: kld=0.00147   cross_entropy=0.00051   overall=0.00099\n",
      "Epoch 94: kld=0.00145   cross_entropy=0.00050   overall=0.00098\n",
      "Epoch 95: kld=0.00143   cross_entropy=0.00050   overall=0.00096\n",
      "Epoch 96: kld=0.00140   cross_entropy=0.00049   overall=0.00095\n",
      "Epoch 97: kld=0.00138   cross_entropy=0.00048   overall=0.00093\n",
      "Epoch 98: kld=0.00136   cross_entropy=0.00047   overall=0.00092\n",
      "Epoch 99: kld=0.00134   cross_entropy=0.00046   overall=0.00090\n",
      "Epoch 100: kld=0.00132   cross_entropy=0.00045   overall=0.00089\n",
      "Epoch 101: kld=0.00130   cross_entropy=0.00045   overall=0.00088\n",
      "Epoch 102: kld=0.00129   cross_entropy=0.00044   overall=0.00086\n",
      "Epoch 103: kld=0.00127   cross_entropy=0.00043   overall=0.00085\n",
      "Epoch 104: kld=0.00125   cross_entropy=0.00042   overall=0.00084\n",
      "Epoch 105: kld=0.00123   cross_entropy=0.00042   overall=0.00082\n",
      "Epoch 106: kld=0.00121   cross_entropy=0.00041   overall=0.00081\n",
      "Epoch 107: kld=0.00120   cross_entropy=0.00040   overall=0.00080\n",
      "Epoch 108: kld=0.00118   cross_entropy=0.00040   overall=0.00079\n",
      "Epoch 109: kld=0.00117   cross_entropy=0.00039   overall=0.00078\n",
      "Epoch 110: kld=0.00115   cross_entropy=0.00038   overall=0.00077\n",
      "Epoch 111: kld=0.00113   cross_entropy=0.00038   overall=0.00076\n",
      "Epoch 112: kld=0.00112   cross_entropy=0.00037   overall=0.00075\n",
      "Epoch 113: kld=0.00110   cross_entropy=0.00037   overall=0.00074\n",
      "Epoch 114: kld=0.00109   cross_entropy=0.00036   overall=0.00073\n",
      "Epoch 115: kld=0.00108   cross_entropy=0.00036   overall=0.00072\n",
      "Epoch 116: kld=0.00106   cross_entropy=0.00035   overall=0.00071\n",
      "Epoch 117: kld=0.00105   cross_entropy=0.00034   overall=0.00070\n",
      "Epoch 118: kld=0.00103   cross_entropy=0.00034   overall=0.00069\n",
      "Epoch 119: kld=0.00102   cross_entropy=0.00033   overall=0.00068\n",
      "Epoch 120: kld=0.00101   cross_entropy=0.00033   overall=0.00067\n",
      "Epoch 121: kld=0.00099   cross_entropy=0.00032   overall=0.00066\n",
      "Epoch 122: kld=0.00098   cross_entropy=0.00032   overall=0.00065\n",
      "Epoch 123: kld=0.00097   cross_entropy=0.00032   overall=0.00064\n",
      "Epoch 124: kld=0.00096   cross_entropy=0.00031   overall=0.00063\n",
      "Epoch 125: kld=0.00095   cross_entropy=0.00031   overall=0.00063\n",
      "Epoch 126: kld=0.00093   cross_entropy=0.00030   overall=0.00062\n",
      "Epoch 127: kld=0.00092   cross_entropy=0.00030   overall=0.00061\n",
      "Epoch 128: kld=0.00091   cross_entropy=0.00029   overall=0.00060\n",
      "Epoch 129: kld=0.00090   cross_entropy=0.00029   overall=0.00060\n",
      "Epoch 130: kld=0.00089   cross_entropy=0.00029   overall=0.00059\n",
      "Epoch 131: kld=0.00088   cross_entropy=0.00028   overall=0.00058\n",
      "Epoch 132: kld=0.00087   cross_entropy=0.00028   overall=0.00057\n",
      "Epoch 133: kld=0.00086   cross_entropy=0.00027   overall=0.00057\n",
      "Epoch 134: kld=0.00085   cross_entropy=0.00027   overall=0.00056\n",
      "Epoch 135: kld=0.00084   cross_entropy=0.00027   overall=0.00055\n",
      "Epoch 136: kld=0.00083   cross_entropy=0.00026   overall=0.00055\n",
      "Epoch 137: kld=0.00082   cross_entropy=0.00026   overall=0.00054\n",
      "Epoch 138: kld=0.00081   cross_entropy=0.00026   overall=0.00053\n",
      "Epoch 139: kld=0.00080   cross_entropy=0.00025   overall=0.00053\n",
      "Epoch 140: kld=0.00079   cross_entropy=0.00025   overall=0.00052\n",
      "Epoch 141: kld=0.00078   cross_entropy=0.00025   overall=0.00051\n",
      "Epoch 142: kld=0.00077   cross_entropy=0.00024   overall=0.00051\n",
      "Epoch 143: kld=0.00077   cross_entropy=0.00024   overall=0.00050\n",
      "Epoch 144: kld=0.00076   cross_entropy=0.00024   overall=0.00050\n",
      "Epoch 145: kld=0.00075   cross_entropy=0.00023   overall=0.00049\n",
      "Epoch 146: kld=0.00074   cross_entropy=0.00023   overall=0.00049\n",
      "Epoch 147: kld=0.00073   cross_entropy=0.00023   overall=0.00048\n",
      "Epoch 148: kld=0.00072   cross_entropy=0.00022   overall=0.00047\n",
      "Epoch 149: kld=0.00072   cross_entropy=0.00022   overall=0.00047\n",
      "Epoch 150: kld=0.00071   cross_entropy=0.00022   overall=0.00046\n",
      "Epoch 151: kld=0.00070   cross_entropy=0.00022   overall=0.00046\n",
      "Epoch 152: kld=0.00069   cross_entropy=0.00021   overall=0.00045\n",
      "Epoch 153: kld=0.00069   cross_entropy=0.00021   overall=0.00045\n",
      "Epoch 154: kld=0.00068   cross_entropy=0.00021   overall=0.00044\n",
      "Epoch 155: kld=0.00067   cross_entropy=0.00021   overall=0.00044\n",
      "Epoch 156: kld=0.00067   cross_entropy=0.00020   overall=0.00043\n",
      "Epoch 157: kld=0.00066   cross_entropy=0.00020   overall=0.00043\n",
      "Epoch 158: kld=0.00065   cross_entropy=0.00020   overall=0.00043\n",
      "Epoch 159: kld=0.00065   cross_entropy=0.00020   overall=0.00042\n",
      "Epoch 160: kld=0.00064   cross_entropy=0.00019   overall=0.00042\n",
      "Epoch 161: kld=0.00063   cross_entropy=0.00019   overall=0.00041\n",
      "Epoch 162: kld=0.00063   cross_entropy=0.00019   overall=0.00041\n",
      "Epoch 163: kld=0.00062   cross_entropy=0.00019   overall=0.00040\n",
      "Epoch 164: kld=0.00061   cross_entropy=0.00018   overall=0.00040\n",
      "Epoch 165: kld=0.00061   cross_entropy=0.00018   overall=0.00039\n",
      "Epoch 166: kld=0.00060   cross_entropy=0.00018   overall=0.00039\n",
      "Epoch 167: kld=0.00059   cross_entropy=0.00018   overall=0.00039\n",
      "Epoch 168: kld=0.00059   cross_entropy=0.00018   overall=0.00038\n",
      "Epoch 169: kld=0.00058   cross_entropy=0.00017   overall=0.00038\n",
      "Epoch 170: kld=0.00058   cross_entropy=0.00017   overall=0.00037\n",
      "Epoch 171: kld=0.00057   cross_entropy=0.00017   overall=0.00037\n",
      "Epoch 172: kld=0.00057   cross_entropy=0.00017   overall=0.00037\n",
      "Epoch 173: kld=0.00056   cross_entropy=0.00017   overall=0.00036\n",
      "Epoch 174: kld=0.00056   cross_entropy=0.00016   overall=0.00036\n",
      "Epoch 175: kld=0.00055   cross_entropy=0.00016   overall=0.00036\n",
      "Epoch 176: kld=0.00054   cross_entropy=0.00016   overall=0.00035\n",
      "Epoch 177: kld=0.00054   cross_entropy=0.00016   overall=0.00035\n",
      "Epoch 178: kld=0.00053   cross_entropy=0.00016   overall=0.00035\n",
      "Epoch 179: kld=0.00053   cross_entropy=0.00016   overall=0.00034\n",
      "Epoch 180: kld=0.00052   cross_entropy=0.00015   overall=0.00034\n",
      "Epoch 181: kld=0.00052   cross_entropy=0.00015   overall=0.00034\n",
      "Epoch 182: kld=0.00051   cross_entropy=0.00015   overall=0.00033\n",
      "Epoch 183: kld=0.00051   cross_entropy=0.00015   overall=0.00033\n",
      "Epoch 184: kld=0.00051   cross_entropy=0.00015   overall=0.00033\n",
      "Epoch 185: kld=0.00050   cross_entropy=0.00015   overall=0.00032\n",
      "Epoch 186: kld=0.00050   cross_entropy=0.00014   overall=0.00032\n",
      "Epoch 187: kld=0.00049   cross_entropy=0.00014   overall=0.00032\n",
      "Epoch 188: kld=0.00049   cross_entropy=0.00014   overall=0.00031\n",
      "Epoch 189: kld=0.00048   cross_entropy=0.00014   overall=0.00031\n",
      "Epoch 190: kld=0.00048   cross_entropy=0.00014   overall=0.00031\n",
      "Epoch 191: kld=0.00047   cross_entropy=0.00014   overall=0.00031\n",
      "Epoch 192: kld=0.00047   cross_entropy=0.00014   overall=0.00030\n",
      "Epoch 193: kld=0.00047   cross_entropy=0.00013   overall=0.00030\n",
      "Epoch 194: kld=0.00046   cross_entropy=0.00013   overall=0.00030\n",
      "Epoch 195: kld=0.00046   cross_entropy=0.00013   overall=0.00029\n",
      "Epoch 196: kld=0.00045   cross_entropy=0.00013   overall=0.00029\n",
      "Epoch 197: kld=0.00045   cross_entropy=0.00013   overall=0.00029\n",
      "Epoch 198: kld=0.00044   cross_entropy=0.00013   overall=0.00029\n",
      "Epoch 199: kld=0.00044   cross_entropy=0.00013   overall=0.00028\n"
     ]
    }
   ],
   "source": [
    "student = Student(num_features, num_classes)\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=3e-4)\n",
    "\n",
    "# Инициализируем политику функции потерь для дистилляции.\n",
    "# В этом примере используется стандартная политика, при которой\n",
    "# ученик учится сразу на распределение логитов учителя (KLD) и на мейнстрим задачу (CE).\n",
    "# Для кастомизации политики, например, для использования других функций потерь или\n",
    "# добавления адаптеров между аутпутами моделей, необходимо наследоваться от класса `AbstractDistillationPolicy`\n",
    "policy = BasicDistillationPolicy(temperature=1.2, alpha=0.5)\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy, optimizer)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cffa932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        57\n",
      "           1       1.00      0.96      0.98        55\n",
      "           2       0.96      1.00      0.98        45\n",
      "           3       1.00      0.89      0.94        47\n",
      "           4       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.97       250\n",
      "   macro avg       0.97      0.97      0.97       250\n",
      "weighted avg       0.97      0.97      0.97       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(student, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f4f84",
   "metadata": {},
   "source": [
    "## Custom policy (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19dccaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class SingleMSEDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def forward(self, teacher_output, student_output, batch, epoch) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        loss_mse = nn.functional.mse_loss(student_output, teacher_output)\n",
    "        loss_dict = {'mse': loss_mse.item()}\n",
    "        return loss_mse, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4fcc668",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mse=6.79457                                     \n",
      "Epoch 1: mse=6.16706                                     \n",
      "Epoch 2: mse=5.59082                                     \n",
      "Epoch 3: mse=5.06709                                     \n",
      "Epoch 4: mse=4.59360                                     \n",
      "Epoch 5: mse=4.16680                                     \n",
      "Epoch 6: mse=3.78282                                     \n",
      "Epoch 7: mse=3.43788                                     \n",
      "Epoch 8: mse=3.12836                                     \n",
      "Epoch 9: mse=2.85094                                     \n",
      "Epoch 10: mse=2.60250                                     \n",
      "Epoch 11: mse=2.38020                                     \n",
      "Epoch 12: mse=2.18141                                     \n",
      "Epoch 13: mse=2.00375                                     \n",
      "Epoch 14: mse=1.84501                                     \n",
      "Epoch 15: mse=1.70321                                     \n",
      "Epoch 16: mse=1.57654                                     \n",
      "Epoch 17: mse=1.46334                                     \n",
      "Epoch 18: mse=1.36215                                     \n",
      "Epoch 19: mse=1.27163                                     \n",
      "Epoch 20: mse=1.19057                                     \n",
      "Epoch 21: mse=1.11790                                     \n",
      "Epoch 22: mse=1.05266                                     \n",
      "Epoch 23: mse=0.99398                                     \n",
      "Epoch 24: mse=0.94112                                     \n",
      "Epoch 25: mse=0.89339                                     \n",
      "Epoch 26: mse=0.85019                                     \n",
      "Epoch 27: mse=0.81100                                     \n",
      "Epoch 28: mse=0.77535                                     \n",
      "Epoch 29: mse=0.74283                                     \n",
      "Epoch 30: mse=0.71310                                     \n",
      "Epoch 31: mse=0.68582                                     \n",
      "Epoch 32: mse=0.66074                                     \n",
      "Epoch 33: mse=0.63761                                     \n",
      "Epoch 34: mse=0.61622                                     \n",
      "Epoch 35: mse=0.59638                                     \n",
      "Epoch 36: mse=0.57795                                     \n",
      "Epoch 37: mse=0.56078                                     \n",
      "Epoch 38: mse=0.54474                                     \n",
      "Epoch 39: mse=0.52974                                     \n",
      "Epoch 40: mse=0.51568                                     \n",
      "Epoch 41: mse=0.50247                                     \n",
      "Epoch 42: mse=0.49004                                     \n",
      "Epoch 43: mse=0.47833                                     \n",
      "Epoch 44: mse=0.46729                                     \n",
      "Epoch 45: mse=0.45685                                     \n",
      "Epoch 46: mse=0.44698                                     \n",
      "Epoch 47: mse=0.43764                                     \n",
      "Epoch 48: mse=0.42878                                     \n",
      "Epoch 49: mse=0.42037                                     \n",
      "Epoch 50: mse=0.41240                                     \n",
      "Epoch 51: mse=0.40482                                     \n",
      "Epoch 52: mse=0.39761                                     \n",
      "Epoch 53: mse=0.39075                                     \n",
      "Epoch 54: mse=0.38422                                     \n",
      "Epoch 55: mse=0.37799                                     \n",
      "Epoch 56: mse=0.37206                                     \n",
      "Epoch 57: mse=0.36641                                     \n",
      "Epoch 58: mse=0.36101                                     \n",
      "Epoch 59: mse=0.35585                                     \n",
      "Epoch 60: mse=0.35093                                     \n",
      "Epoch 61: mse=0.34623                                     \n",
      "Epoch 62: mse=0.34173                                     \n",
      "Epoch 63: mse=0.33743                                     \n",
      "Epoch 64: mse=0.33331                                     \n",
      "Epoch 65: mse=0.32937                                     \n",
      "Epoch 66: mse=0.32560                                     \n",
      "Epoch 67: mse=0.32198                                     \n",
      "Epoch 68: mse=0.31852                                     \n",
      "Epoch 69: mse=0.31520                                     \n",
      "Epoch 70: mse=0.31202                                     \n",
      "Epoch 71: mse=0.30896                                     \n",
      "Epoch 72: mse=0.30603                                     \n",
      "Epoch 73: mse=0.30322                                     \n",
      "Epoch 74: mse=0.30052                                     \n",
      "Epoch 75: mse=0.29793                                     \n",
      "Epoch 76: mse=0.29544                                     \n",
      "Epoch 77: mse=0.29304                                     \n",
      "Epoch 78: mse=0.29074                                     \n",
      "Epoch 79: mse=0.28853                                     \n",
      "Epoch 80: mse=0.28640                                     \n",
      "Epoch 81: mse=0.28435                                     \n",
      "Epoch 82: mse=0.28238                                     \n",
      "Epoch 83: mse=0.28049                                     \n",
      "Epoch 84: mse=0.27866                                     \n",
      "Epoch 85: mse=0.27691                                     \n",
      "Epoch 86: mse=0.27521                                     \n",
      "Epoch 87: mse=0.27359                                     \n",
      "Epoch 88: mse=0.27202                                     \n",
      "Epoch 89: mse=0.27050                                     \n",
      "Epoch 90: mse=0.26905                                     \n",
      "Epoch 91: mse=0.26764                                     \n",
      "Epoch 92: mse=0.26629                                     \n",
      "Epoch 93: mse=0.26498                                     \n",
      "Epoch 94: mse=0.26373                                     \n",
      "Epoch 95: mse=0.26251                                     \n",
      "Epoch 96: mse=0.26134                                     \n",
      "Epoch 97: mse=0.26021                                     \n",
      "Epoch 98: mse=0.25912                                     \n",
      "Epoch 99: mse=0.25807                                     \n",
      "Epoch 100: mse=0.25706                                     \n",
      "Epoch 101: mse=0.25608                                     \n",
      "Epoch 102: mse=0.25513                                     \n",
      "Epoch 103: mse=0.25422                                     \n",
      "Epoch 104: mse=0.25334                                     \n",
      "Epoch 105: mse=0.25248                                     \n",
      "Epoch 106: mse=0.25166                                     \n",
      "Epoch 107: mse=0.25087                                     \n",
      "Epoch 108: mse=0.25010                                     \n",
      "Epoch 109: mse=0.24936                                     \n",
      "Epoch 110: mse=0.24864                                     \n",
      "Epoch 111: mse=0.24795                                     \n",
      "Epoch 112: mse=0.24728                                     \n",
      "Epoch 113: mse=0.24663                                     \n",
      "Epoch 114: mse=0.24601                                     \n",
      "Epoch 115: mse=0.24540                                     \n",
      "Epoch 116: mse=0.24482                                     \n",
      "Epoch 117: mse=0.24425                                     \n",
      "Epoch 118: mse=0.24370                                     \n",
      "Epoch 119: mse=0.24317                                     \n",
      "Epoch 120: mse=0.24266                                     \n",
      "Epoch 121: mse=0.24217                                     \n",
      "Epoch 122: mse=0.24169                                     \n",
      "Epoch 123: mse=0.24122                                     \n",
      "Epoch 124: mse=0.24077                                     \n",
      "Epoch 125: mse=0.24034                                     \n",
      "Epoch 126: mse=0.23992                                     \n",
      "Epoch 127: mse=0.23951                                     \n",
      "Epoch 128: mse=0.23911                                     \n",
      "Epoch 129: mse=0.23873                                     \n",
      "Epoch 130: mse=0.23836                                     \n",
      "Epoch 131: mse=0.23800                                     \n",
      "Epoch 132: mse=0.23765                                     \n",
      "Epoch 133: mse=0.23731                                     \n",
      "Epoch 134: mse=0.23698                                     \n",
      "Epoch 135: mse=0.23666                                     \n",
      "Epoch 136: mse=0.23636                                     \n",
      "Epoch 137: mse=0.23606                                     \n",
      "Epoch 138: mse=0.23577                                     \n",
      "Epoch 139: mse=0.23549                                     \n",
      "Epoch 140: mse=0.23521                                     \n",
      "Epoch 141: mse=0.23495                                     \n",
      "Epoch 142: mse=0.23469                                     \n",
      "Epoch 143: mse=0.23444                                     \n",
      "Epoch 144: mse=0.23419                                     \n",
      "Epoch 145: mse=0.23396                                     \n",
      "Epoch 146: mse=0.23373                                     \n",
      "Epoch 147: mse=0.23351                                     \n",
      "Epoch 148: mse=0.23329                                     \n",
      "Epoch 149: mse=0.23308                                     \n",
      "Epoch 150: mse=0.23287                                     \n",
      "Epoch 151: mse=0.23267                                     \n",
      "Epoch 152: mse=0.23248                                     \n",
      "Epoch 153: mse=0.23229                                     \n",
      "Epoch 154: mse=0.23210                                     \n",
      "Epoch 155: mse=0.23192                                     \n",
      "Epoch 156: mse=0.23175                                     \n",
      "Epoch 157: mse=0.23158                                     \n",
      "Epoch 158: mse=0.23141                                     \n",
      "Epoch 159: mse=0.23125                                     \n",
      "Epoch 160: mse=0.23109                                     \n",
      "Epoch 161: mse=0.23094                                     \n",
      "Epoch 162: mse=0.23079                                     \n",
      "Epoch 163: mse=0.23064                                     \n",
      "Epoch 164: mse=0.23050                                     \n",
      "Epoch 165: mse=0.23036                                     \n",
      "Epoch 166: mse=0.23022                                     \n",
      "Epoch 167: mse=0.23008                                     \n",
      "Epoch 168: mse=0.22995                                     \n",
      "Epoch 169: mse=0.22983                                     \n",
      "Epoch 170: mse=0.22970                                     \n",
      "Epoch 171: mse=0.22958                                     \n",
      "Epoch 172: mse=0.22946                                     \n",
      "Epoch 173: mse=0.22934                                     \n",
      "Epoch 174: mse=0.22923                                     \n",
      "Epoch 175: mse=0.22911                                     \n",
      "Epoch 176: mse=0.22900                                     \n",
      "Epoch 177: mse=0.22889                                     \n",
      "Epoch 178: mse=0.22879                                     \n",
      "Epoch 179: mse=0.22868                                     \n",
      "Epoch 180: mse=0.22858                                     \n",
      "Epoch 181: mse=0.22848                                     \n",
      "Epoch 182: mse=0.22838                                     \n",
      "Epoch 183: mse=0.22829                                     \n",
      "Epoch 184: mse=0.22819                                     \n",
      "Epoch 185: mse=0.22810                                     \n",
      "Epoch 186: mse=0.22801                                     \n",
      "Epoch 187: mse=0.22792                                     \n",
      "Epoch 188: mse=0.22783                                     \n",
      "Epoch 189: mse=0.22774                                     \n",
      "Epoch 190: mse=0.22766                                     \n",
      "Epoch 191: mse=0.22757                                     \n",
      "Epoch 192: mse=0.22749                                     \n",
      "Epoch 193: mse=0.22741                                     \n",
      "Epoch 194: mse=0.22733                                     \n",
      "Epoch 195: mse=0.22725                                     \n",
      "Epoch 196: mse=0.22717                                     \n",
      "Epoch 197: mse=0.22709                                     \n",
      "Epoch 198: mse=0.22701                                     \n",
      "Epoch 199: mse=0.22694                                     \n"
     ]
    }
   ],
   "source": [
    "student = Student(num_features, num_classes)\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=3e-4)\n",
    "\n",
    "policy = SingleMSEDistillationPolicy()\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy, optimizer)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c336696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        57\n",
      "           1       1.00      1.00      1.00        55\n",
      "           2       0.98      1.00      0.99        45\n",
      "           3       1.00      0.98      0.99        47\n",
      "           4       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           0.99       250\n",
      "   macro avg       0.99      0.99      0.99       250\n",
      "weighted avg       0.99      0.99      0.99       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(student, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53299ad8",
   "metadata": {},
   "source": [
    "## Advanced policy\n",
    "**CE + MSE with scale decay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4abe6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e569c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class AdvancedDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def __init__(self, n_epochs: int, adapter_mapping: Optional[Tuple[int, int]] = None):\n",
    "        super().__init__()\n",
    "        self.n_epochs = n_epochs\n",
    "    \n",
    "    def forward(self, teacher_output, student_output, batch, epoch) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        alpha = exp((epoch + 1) / self.n_epochs)\n",
    "        loss_mse = nn.functional.mse_loss(student_output, teacher_output)\n",
    "        loss_ce = nn.functional.cross_entropy(student_output, batch[1])\n",
    "        overall = loss_mse * alpha + loss_ce * (1 - alpha)\n",
    "        scalars_dict = {\n",
    "            'mse': loss_mse.item(),\n",
    "            'cross_entropy': loss_ce.item(),\n",
    "            'overall': overall.item(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "        return overall, scalars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e65b94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mse=6.53153   cross_entropy=0.52086   overall=6.56166   alpha=0.09222\n",
      "Epoch 1: mse=5.90396   cross_entropy=0.43576   overall=5.95892   alpha=0.09269\n",
      "Epoch 2: mse=5.32849   cross_entropy=0.35798   overall=5.40361   alpha=0.09315\n",
      "Epoch 3: mse=4.80595   cross_entropy=0.28936   overall=4.89719   alpha=0.09362\n",
      "Epoch 4: mse=4.33409   cross_entropy=0.23106   overall=4.43796   alpha=0.09409\n",
      "Epoch 5: mse=3.90946   cross_entropy=0.18301   overall=4.02295   alpha=0.09456\n",
      "Epoch 6: mse=3.52830   cross_entropy=0.14486   overall=3.64882   alpha=0.09503\n",
      "Epoch 7: mse=3.18693   cross_entropy=0.11538   overall=3.31229   alpha=0.09551\n",
      "Epoch 8: mse=2.88185   cross_entropy=0.09211   overall=3.01026   alpha=0.09599\n",
      "Epoch 9: mse=2.60978   cross_entropy=0.07313   overall=2.73983   alpha=0.09647\n",
      "Epoch 10: mse=2.36764   cross_entropy=0.05762   overall=2.49825   alpha=0.09695\n",
      "Epoch 11: mse=2.15257   cross_entropy=0.04525   overall=2.28288   alpha=0.09744\n",
      "Epoch 12: mse=1.96192   cross_entropy=0.03534   overall=2.09130   alpha=0.09793\n",
      "Epoch 13: mse=1.79320   cross_entropy=0.02739   overall=1.92123   alpha=0.09842\n",
      "Epoch 14: mse=1.64412   cross_entropy=0.02124   overall=1.77051   alpha=0.09891\n",
      "Epoch 15: mse=1.51255   cross_entropy=0.01667   overall=1.63714   alpha=0.09941\n",
      "Epoch 16: mse=1.39655   cross_entropy=0.01327   overall=1.51927   alpha=0.09990\n",
      "Epoch 17: mse=1.29432   cross_entropy=0.01072   overall=1.41520   alpha=0.10040\n",
      "Epoch 18: mse=1.20423   cross_entropy=0.00879   overall=1.32337   alpha=0.10091\n",
      "Epoch 19: mse=1.12481   cross_entropy=0.00733   overall=1.24233   alpha=0.10141\n",
      "Epoch 20: mse=1.05471   cross_entropy=0.00621   overall=1.17080   alpha=0.10192\n",
      "Epoch 21: mse=0.99275   cross_entropy=0.00532   overall=1.10757   alpha=0.10243\n",
      "Epoch 22: mse=0.93786   cross_entropy=0.00461   overall=1.05159   alpha=0.10295\n",
      "Epoch 23: mse=0.88908   cross_entropy=0.00403   overall=1.00192   alpha=0.10346\n",
      "Epoch 24: mse=0.84559   cross_entropy=0.00355   overall=0.95770   alpha=0.10398\n",
      "Epoch 25: mse=0.80665   cross_entropy=0.00314   overall=0.91820   alpha=0.10450\n",
      "Epoch 26: mse=0.77164   cross_entropy=0.00280   overall=0.88276   alpha=0.10503\n",
      "Epoch 27: mse=0.74000   cross_entropy=0.00250   overall=0.85082   alpha=0.10555\n",
      "Epoch 28: mse=0.71126   cross_entropy=0.00225   overall=0.82189   alpha=0.10608\n",
      "Epoch 29: mse=0.68501   cross_entropy=0.00202   overall=0.79554   alpha=0.10661\n",
      "Epoch 30: mse=0.66091   cross_entropy=0.00182   overall=0.77141   alpha=0.10715\n",
      "Epoch 31: mse=0.63866   cross_entropy=0.00164   overall=0.74919   alpha=0.10769\n",
      "Epoch 32: mse=0.61802   cross_entropy=0.00149   overall=0.72863   alpha=0.10822\n",
      "Epoch 33: mse=0.59879   cross_entropy=0.00135   overall=0.70949   alpha=0.10877\n",
      "Epoch 34: mse=0.58077   cross_entropy=0.00122   overall=0.69161   alpha=0.10931\n",
      "Epoch 35: mse=0.56385   cross_entropy=0.00111   overall=0.67483   alpha=0.10986\n",
      "Epoch 36: mse=0.54788   cross_entropy=0.00100   overall=0.65901   alpha=0.11041\n",
      "Epoch 37: mse=0.53277   cross_entropy=0.00091   overall=0.64406   alpha=0.11096\n",
      "Epoch 38: mse=0.51844   cross_entropy=0.00083   overall=0.62989   alpha=0.11152\n",
      "Epoch 39: mse=0.50482   cross_entropy=0.00075   overall=0.61642   alpha=0.11208\n",
      "Epoch 40: mse=0.49185   cross_entropy=0.00068   overall=0.60360   alpha=0.11264\n",
      "Epoch 41: mse=0.47948   cross_entropy=0.00062   overall=0.59138   alpha=0.11321\n",
      "Epoch 42: mse=0.46767   cross_entropy=0.00056   overall=0.57971   alpha=0.11377\n",
      "Epoch 43: mse=0.45639   cross_entropy=0.00051   overall=0.56857   alpha=0.11434\n",
      "Epoch 44: mse=0.44561   cross_entropy=0.00047   overall=0.55793   alpha=0.11492\n",
      "Epoch 45: mse=0.43530   cross_entropy=0.00043   overall=0.54775   alpha=0.11549\n",
      "Epoch 46: mse=0.42543   cross_entropy=0.00039   overall=0.53803   alpha=0.11607\n",
      "Epoch 47: mse=0.41600   cross_entropy=0.00036   overall=0.52874   alpha=0.11665\n",
      "Epoch 48: mse=0.40698   cross_entropy=0.00033   overall=0.51987   alpha=0.11724\n",
      "Epoch 49: mse=0.39835   cross_entropy=0.00030   overall=0.51141   alpha=0.11783\n",
      "Epoch 50: mse=0.39010   cross_entropy=0.00028   overall=0.50333   alpha=0.11842\n",
      "Epoch 51: mse=0.38221   cross_entropy=0.00025   overall=0.49563   alpha=0.11901\n",
      "Epoch 52: mse=0.37468   cross_entropy=0.00023   overall=0.48830   alpha=0.11961\n",
      "Epoch 53: mse=0.36748   cross_entropy=0.00022   overall=0.48132   alpha=0.12021\n",
      "Epoch 54: mse=0.36060   cross_entropy=0.00020   overall=0.47468   alpha=0.12081\n",
      "Epoch 55: mse=0.35404   cross_entropy=0.00019   overall=0.46838   alpha=0.12141\n",
      "Epoch 56: mse=0.34777   cross_entropy=0.00017   overall=0.46240   alpha=0.12202\n",
      "Epoch 57: mse=0.34180   cross_entropy=0.00016   overall=0.45673   alpha=0.12263\n",
      "Epoch 58: mse=0.33610   cross_entropy=0.00015   overall=0.45137   alpha=0.12325\n",
      "Epoch 59: mse=0.33066   cross_entropy=0.00014   overall=0.44630   alpha=0.12387\n",
      "Epoch 60: mse=0.32548   cross_entropy=0.00013   overall=0.44151   alpha=0.12449\n",
      "Epoch 61: mse=0.32055   cross_entropy=0.00012   overall=0.43700   alpha=0.12511\n",
      "Epoch 62: mse=0.31584   cross_entropy=0.00011   overall=0.43274   alpha=0.12574\n",
      "Epoch 63: mse=0.31136   cross_entropy=0.00011   overall=0.42875   alpha=0.12637\n",
      "Epoch 64: mse=0.30710   cross_entropy=0.00010   overall=0.42500   alpha=0.12700\n",
      "Epoch 65: mse=0.30304   cross_entropy=0.00010   overall=0.42148   alpha=0.12764\n",
      "Epoch 66: mse=0.29918   cross_entropy=0.00009   overall=0.41820   alpha=0.12828\n",
      "Epoch 67: mse=0.29550   cross_entropy=0.00009   overall=0.41513   alpha=0.12892\n",
      "Epoch 68: mse=0.29200   cross_entropy=0.00008   overall=0.41227   alpha=0.12957\n",
      "Epoch 69: mse=0.28868   cross_entropy=0.00008   overall=0.40962   alpha=0.13022\n",
      "Epoch 70: mse=0.28551   cross_entropy=0.00007   overall=0.40716   alpha=0.13087\n",
      "Epoch 71: mse=0.28250   cross_entropy=0.00007   overall=0.40489   alpha=0.13153\n",
      "Epoch 72: mse=0.27964   cross_entropy=0.00007   overall=0.40280   alpha=0.13219\n",
      "Epoch 73: mse=0.27692   cross_entropy=0.00006   overall=0.40088   alpha=0.13285\n",
      "Epoch 74: mse=0.27433   cross_entropy=0.00006   overall=0.39912   alpha=0.13351\n",
      "Epoch 75: mse=0.27187   cross_entropy=0.00006   overall=0.39753   alpha=0.13418\n",
      "Epoch 76: mse=0.26954   cross_entropy=0.00006   overall=0.39609   alpha=0.13486\n",
      "Epoch 77: mse=0.26732   cross_entropy=0.00005   overall=0.39480   alpha=0.13553\n",
      "Epoch 78: mse=0.26521   cross_entropy=0.00005   overall=0.39364   alpha=0.13621\n",
      "Epoch 79: mse=0.26320   cross_entropy=0.00005   overall=0.39262   alpha=0.13689\n",
      "Epoch 80: mse=0.26129   cross_entropy=0.00005   overall=0.39173   alpha=0.13758\n",
      "Epoch 81: mse=0.25948   cross_entropy=0.00005   overall=0.39097   alpha=0.13827\n",
      "Epoch 82: mse=0.25776   cross_entropy=0.00005   overall=0.39032   alpha=0.13896\n",
      "Epoch 83: mse=0.25612   cross_entropy=0.00004   overall=0.38979   alpha=0.13966\n",
      "Epoch 84: mse=0.25457   cross_entropy=0.00004   overall=0.38936   alpha=0.14036\n",
      "Epoch 85: mse=0.25309   cross_entropy=0.00004   overall=0.38904   alpha=0.14106\n",
      "Epoch 86: mse=0.25168   cross_entropy=0.00004   overall=0.38882   alpha=0.14177\n",
      "Epoch 87: mse=0.25035   cross_entropy=0.00004   overall=0.38870   alpha=0.14248\n",
      "Epoch 88: mse=0.24908   cross_entropy=0.00004   overall=0.38866   alpha=0.14320\n",
      "Epoch 89: mse=0.24787   cross_entropy=0.00004   overall=0.38872   alpha=0.14391\n",
      "Epoch 90: mse=0.24672   cross_entropy=0.00004   overall=0.38886   alpha=0.14463\n",
      "Epoch 91: mse=0.24563   cross_entropy=0.00004   overall=0.38908   alpha=0.14536\n",
      "Epoch 92: mse=0.24460   cross_entropy=0.00004   overall=0.38938   alpha=0.14609\n",
      "Epoch 93: mse=0.24361   cross_entropy=0.00004   overall=0.38975   alpha=0.14682\n",
      "Epoch 94: mse=0.24267   cross_entropy=0.00003   overall=0.39020   alpha=0.14756\n",
      "Epoch 95: mse=0.24178   cross_entropy=0.00003   overall=0.39071   alpha=0.14830\n",
      "Epoch 96: mse=0.24093   cross_entropy=0.00003   overall=0.39129   alpha=0.14904\n",
      "Epoch 97: mse=0.24012   cross_entropy=0.00003   overall=0.39193   alpha=0.14979\n",
      "Epoch 98: mse=0.23935   cross_entropy=0.00003   overall=0.39263   alpha=0.15054\n",
      "Epoch 99: mse=0.23862   cross_entropy=0.00003   overall=0.39339   alpha=0.15129\n",
      "Epoch 100: mse=0.23792   cross_entropy=0.00003   overall=0.39421   alpha=0.15205\n",
      "Epoch 101: mse=0.23726   cross_entropy=0.00003   overall=0.39508   alpha=0.15281\n",
      "Epoch 102: mse=0.23662   cross_entropy=0.00003   overall=0.39600   alpha=0.15358\n",
      "Epoch 103: mse=0.23602   cross_entropy=0.00003   overall=0.39697   alpha=0.15435\n",
      "Epoch 104: mse=0.23545   cross_entropy=0.00003   overall=0.39799   alpha=0.15512\n",
      "Epoch 105: mse=0.23490   cross_entropy=0.00003   overall=0.39906   alpha=0.15590\n",
      "Epoch 106: mse=0.23438   cross_entropy=0.00003   overall=0.40017   alpha=0.15668\n",
      "Epoch 107: mse=0.23388   cross_entropy=0.00003   overall=0.40132   alpha=0.15747\n",
      "Epoch 108: mse=0.23340   cross_entropy=0.00003   overall=0.40251   alpha=0.15826\n",
      "Epoch 109: mse=0.23295   cross_entropy=0.00003   overall=0.40374   alpha=0.15905\n",
      "Epoch 110: mse=0.23252   cross_entropy=0.00003   overall=0.40501   alpha=0.15985\n",
      "Epoch 111: mse=0.23211   cross_entropy=0.00003   overall=0.40632   alpha=0.16065\n",
      "Epoch 112: mse=0.23171   cross_entropy=0.00003   overall=0.40766   alpha=0.16145\n",
      "Epoch 113: mse=0.23133   cross_entropy=0.00003   overall=0.40904   alpha=0.16226\n",
      "Epoch 114: mse=0.23097   cross_entropy=0.00003   overall=0.41045   alpha=0.16308\n",
      "Epoch 115: mse=0.23063   cross_entropy=0.00003   overall=0.41189   alpha=0.16389\n",
      "Epoch 116: mse=0.23030   cross_entropy=0.00003   overall=0.41336   alpha=0.16471\n",
      "Epoch 117: mse=0.22998   cross_entropy=0.00003   overall=0.41487   alpha=0.16554\n",
      "Epoch 118: mse=0.22968   cross_entropy=0.00003   overall=0.41640   alpha=0.16637\n",
      "Epoch 119: mse=0.22939   cross_entropy=0.00003   overall=0.41796   alpha=0.16720\n",
      "Epoch 120: mse=0.22912   cross_entropy=0.00003   overall=0.41955   alpha=0.16804\n",
      "Epoch 121: mse=0.22885   cross_entropy=0.00003   overall=0.42117   alpha=0.16888\n",
      "Epoch 122: mse=0.22860   cross_entropy=0.00003   overall=0.42281   alpha=0.16973\n",
      "Epoch 123: mse=0.22836   cross_entropy=0.00003   overall=0.42448   alpha=0.17058\n",
      "Epoch 124: mse=0.22812   cross_entropy=0.00003   overall=0.42617   alpha=0.17144\n",
      "Epoch 125: mse=0.22790   cross_entropy=0.00003   overall=0.42788   alpha=0.17230\n",
      "Epoch 126: mse=0.22768   cross_entropy=0.00003   overall=0.42962   alpha=0.17316\n",
      "Epoch 127: mse=0.22748   cross_entropy=0.00003   overall=0.43139   alpha=0.17403\n",
      "Epoch 128: mse=0.22728   cross_entropy=0.00003   overall=0.43317   alpha=0.17490\n",
      "Epoch 129: mse=0.22709   cross_entropy=0.00003   overall=0.43498   alpha=0.17578\n",
      "Epoch 130: mse=0.22691   cross_entropy=0.00003   overall=0.43681   alpha=0.17666\n",
      "Epoch 131: mse=0.22673   cross_entropy=0.00003   overall=0.43865   alpha=0.17754\n",
      "Epoch 132: mse=0.22656   cross_entropy=0.00003   overall=0.44052   alpha=0.17843\n",
      "Epoch 133: mse=0.22640   cross_entropy=0.00003   overall=0.44241   alpha=0.17933\n",
      "Epoch 134: mse=0.22624   cross_entropy=0.00003   overall=0.44432   alpha=0.18023\n",
      "Epoch 135: mse=0.22609   cross_entropy=0.00003   overall=0.44625   alpha=0.18113\n",
      "Epoch 136: mse=0.22595   cross_entropy=0.00003   overall=0.44820   alpha=0.18204\n",
      "Epoch 137: mse=0.22581   cross_entropy=0.00003   overall=0.45017   alpha=0.18295\n",
      "Epoch 138: mse=0.22567   cross_entropy=0.00003   overall=0.45216   alpha=0.18387\n",
      "Epoch 139: mse=0.22554   cross_entropy=0.00003   overall=0.45416   alpha=0.18479\n",
      "Epoch 140: mse=0.22542   cross_entropy=0.00003   overall=0.45618   alpha=0.18571\n",
      "Epoch 141: mse=0.22530   cross_entropy=0.00003   overall=0.45822   alpha=0.18665\n",
      "Epoch 142: mse=0.22518   cross_entropy=0.00003   overall=0.46028   alpha=0.18758\n",
      "Epoch 143: mse=0.22507   cross_entropy=0.00002   overall=0.46236   alpha=0.18852\n",
      "Epoch 144: mse=0.22496   cross_entropy=0.00002   overall=0.46445   alpha=0.18947\n",
      "Epoch 145: mse=0.22485   cross_entropy=0.00002   overall=0.46656   alpha=0.19042\n",
      "Epoch 146: mse=0.22475   cross_entropy=0.00002   overall=0.46868   alpha=0.19137\n",
      "Epoch 147: mse=0.22465   cross_entropy=0.00002   overall=0.47083   alpha=0.19233\n",
      "Epoch 148: mse=0.22456   cross_entropy=0.00002   overall=0.47299   alpha=0.19329\n",
      "Epoch 149: mse=0.22446   cross_entropy=0.00002   overall=0.47516   alpha=0.19426\n",
      "Epoch 150: mse=0.22437   cross_entropy=0.00002   overall=0.47735   alpha=0.19524\n",
      "Epoch 151: mse=0.22429   cross_entropy=0.00002   overall=0.47956   alpha=0.19622\n",
      "Epoch 152: mse=0.22420   cross_entropy=0.00002   overall=0.48178   alpha=0.19720\n",
      "Epoch 153: mse=0.22412   cross_entropy=0.00002   overall=0.48402   alpha=0.19819\n",
      "Epoch 154: mse=0.22404   cross_entropy=0.00002   overall=0.48627   alpha=0.19918\n",
      "Epoch 155: mse=0.22397   cross_entropy=0.00002   overall=0.48854   alpha=0.20018\n",
      "Epoch 156: mse=0.22389   cross_entropy=0.00002   overall=0.49083   alpha=0.20118\n",
      "Epoch 157: mse=0.22382   cross_entropy=0.00002   overall=0.49313   alpha=0.20219\n",
      "Epoch 158: mse=0.22375   cross_entropy=0.00002   overall=0.49545   alpha=0.20320\n",
      "Epoch 159: mse=0.22368   cross_entropy=0.00002   overall=0.49778   alpha=0.20422\n",
      "Epoch 160: mse=0.22361   cross_entropy=0.00002   overall=0.50012   alpha=0.20525\n",
      "Epoch 161: mse=0.22355   cross_entropy=0.00002   overall=0.50248   alpha=0.20628\n",
      "Epoch 162: mse=0.22349   cross_entropy=0.00002   overall=0.50486   alpha=0.20731\n",
      "Epoch 163: mse=0.22342   cross_entropy=0.00002   overall=0.50725   alpha=0.20835\n",
      "Epoch 164: mse=0.22336   cross_entropy=0.00002   overall=0.50966   alpha=0.20939\n",
      "Epoch 165: mse=0.22331   cross_entropy=0.00002   overall=0.51208   alpha=0.21044\n",
      "Epoch 166: mse=0.22325   cross_entropy=0.00002   overall=0.51452   alpha=0.21150\n",
      "Epoch 167: mse=0.22319   cross_entropy=0.00002   overall=0.51697   alpha=0.21256\n",
      "Epoch 168: mse=0.22314   cross_entropy=0.00002   overall=0.51943   alpha=0.21362\n",
      "Epoch 169: mse=0.22309   cross_entropy=0.00002   overall=0.52191   alpha=0.21469\n",
      "Epoch 170: mse=0.22304   cross_entropy=0.00002   overall=0.52441   alpha=0.21577\n",
      "Epoch 171: mse=0.22299   cross_entropy=0.00002   overall=0.52692   alpha=0.21685\n",
      "Epoch 172: mse=0.22294   cross_entropy=0.00002   overall=0.52944   alpha=0.21794\n",
      "Epoch 173: mse=0.22289   cross_entropy=0.00002   overall=0.53198   alpha=0.21903\n",
      "Epoch 174: mse=0.22284   cross_entropy=0.00002   overall=0.53453   alpha=0.22013\n",
      "Epoch 175: mse=0.22279   cross_entropy=0.00002   overall=0.53710   alpha=0.22123\n",
      "Epoch 176: mse=0.22275   cross_entropy=0.00002   overall=0.53968   alpha=0.22234\n",
      "Epoch 177: mse=0.22271   cross_entropy=0.00002   overall=0.54228   alpha=0.22346\n",
      "Epoch 178: mse=0.22266   cross_entropy=0.00002   overall=0.54489   alpha=0.22458\n",
      "Epoch 179: mse=0.22262   cross_entropy=0.00002   overall=0.54752   alpha=0.22570\n",
      "Epoch 180: mse=0.22258   cross_entropy=0.00002   overall=0.55016   alpha=0.22683\n",
      "Epoch 181: mse=0.22254   cross_entropy=0.00002   overall=0.55282   alpha=0.22797\n",
      "Epoch 182: mse=0.22250   cross_entropy=0.00002   overall=0.55549   alpha=0.22911\n",
      "Epoch 183: mse=0.22246   cross_entropy=0.00002   overall=0.55817   alpha=0.23026\n",
      "Epoch 184: mse=0.22242   cross_entropy=0.00002   overall=0.56088   alpha=0.23141\n",
      "Epoch 185: mse=0.22238   cross_entropy=0.00002   overall=0.56359   alpha=0.23257\n",
      "Epoch 186: mse=0.22234   cross_entropy=0.00002   overall=0.56632   alpha=0.23374\n",
      "Epoch 187: mse=0.22231   cross_entropy=0.00002   overall=0.56906   alpha=0.23491\n",
      "Epoch 188: mse=0.22227   cross_entropy=0.00002   overall=0.57182   alpha=0.23609\n",
      "Epoch 189: mse=0.22224   cross_entropy=0.00002   overall=0.57460   alpha=0.23727\n",
      "Epoch 190: mse=0.22220   cross_entropy=0.00002   overall=0.57739   alpha=0.23846\n",
      "Epoch 191: mse=0.22217   cross_entropy=0.00002   overall=0.58019   alpha=0.23966\n",
      "Epoch 192: mse=0.22213   cross_entropy=0.00002   overall=0.58301   alpha=0.24086\n",
      "Epoch 193: mse=0.22210   cross_entropy=0.00002   overall=0.58585   alpha=0.24207\n",
      "Epoch 194: mse=0.22207   cross_entropy=0.00002   overall=0.58870   alpha=0.24328\n",
      "Epoch 195: mse=0.22203   cross_entropy=0.00002   overall=0.59156   alpha=0.24450\n",
      "Epoch 196: mse=0.22200   cross_entropy=0.00002   overall=0.59444   alpha=0.24572\n",
      "Epoch 197: mse=0.22197   cross_entropy=0.00002   overall=0.59733   alpha=0.24696\n",
      "Epoch 198: mse=0.22194   cross_entropy=0.00002   overall=0.60024   alpha=0.24819\n",
      "Epoch 199: mse=0.22191   cross_entropy=0.00002   overall=0.60317   alpha=0.24944\n"
     ]
    }
   ],
   "source": [
    "student = Student(num_features, num_classes)\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=3e-4)\n",
    "\n",
    "policy = AdvancedDistillationPolicy(n_epochs)\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy, optimizer)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b3f9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        57\n",
      "           1       1.00      1.00      1.00        55\n",
      "           2       0.98      1.00      0.99        45\n",
      "           3       1.00      0.98      0.99        47\n",
      "           4       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           0.99       250\n",
      "   macro avg       0.99      0.99      0.99       250\n",
      "weighted avg       0.99      0.99      0.99       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(student, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5156c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
