{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8b1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from squeezer.criterion import distill_loss\n",
    "from squeezer.distiller import Distiller\n",
    "from squeezer.policy import AbstractDistillationPolicy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d086e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa3ed17e350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0xDEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0147f1",
   "metadata": {},
   "source": [
    "# Models\n",
    "Объявляем модель-учитель побольше и модель-ученик поменьше.  \n",
    "Тип возвращаемого значения должен наследоваться от класса `ModelOutput` (или быть им)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7386fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = self.network(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc95edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.network = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = self.network(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ecdee",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4131c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(length: int = 10000, num_features: int = 20, num_classes: int = 4, batch_size: int = 64):\n",
    "    data_tensor = torch.randn(length, num_features)\n",
    "    target_tensor = torch.randint(high=num_classes, size=(length,))\n",
    "    dataset = TensorDataset(data_tensor, target_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6451c97",
   "metadata": {},
   "source": [
    "# Distiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d406ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDistiller(Distiller):\n",
    "    def teacher_forward(self, batch):\n",
    "        return self.teacher(batch[0])\n",
    "    \n",
    "    def student_forward(self, batch):\n",
    "        return self.student(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50ed71",
   "metadata": {},
   "source": [
    "# Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e607e",
   "metadata": {},
   "source": [
    "## Basic policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2426cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class BasicDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def __init__(self, temperature: float = 1.0, alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, teacher_output, student_output, batch, epoch: int) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        loss_kld, loss_ce, overall = distill_loss(\n",
    "            teacher_logits=teacher_output,\n",
    "            student_logits=student_output,\n",
    "            labels=batch[1],\n",
    "            temperature=self.temperature,\n",
    "            alpha=self.alpha\n",
    "        )\n",
    "        loss_dict = {\n",
    "            'kld': loss_kld.item(),\n",
    "            'cross_entropy': loss_ce.item(),\n",
    "            'overall': overall.item(),\n",
    "        }\n",
    "        return overall, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bbd9721",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: kld=0.00085   cross_entropy=0.00974   overall=0.00085      \n",
      "Epoch 1: kld=0.00069   cross_entropy=0.00958   overall=0.00069        \n",
      "Epoch 2: kld=0.00055   cross_entropy=0.00945   overall=0.00055       \n",
      "Epoch 3: kld=0.00043   cross_entropy=0.00934   overall=0.00043        \n",
      "Epoch 4: kld=0.00033   cross_entropy=0.00926   overall=0.00033        \n",
      "Epoch 5: kld=0.00025   cross_entropy=0.00920   overall=0.00025        \n",
      "Epoch 6: kld=0.00019   cross_entropy=0.00916   overall=0.00019        \n",
      "Epoch 7: kld=0.00014   cross_entropy=0.00913   overall=0.00014      \n",
      "Epoch 8: kld=0.00011   cross_entropy=0.00912   overall=0.00011       \n",
      "Epoch 9: kld=0.00008   cross_entropy=0.00911   overall=0.00008      \n",
      "Epoch 10: kld=0.00006   cross_entropy=0.00911   overall=0.00006        \n",
      "Epoch 11: kld=0.00005   cross_entropy=0.00912   overall=0.00005      \n",
      "Epoch 12: kld=0.00004   cross_entropy=0.00913   overall=0.00004      \n",
      "Epoch 13: kld=0.00003   cross_entropy=0.00914   overall=0.00003      \n",
      "Epoch 14: kld=0.00003   cross_entropy=0.00915   overall=0.00003        \n",
      "Epoch 15: kld=0.00002   cross_entropy=0.00916   overall=0.00002      \n",
      "Epoch 16: kld=0.00002   cross_entropy=0.00917   overall=0.00002        \n",
      "Epoch 17: kld=0.00002   cross_entropy=0.00918   overall=0.00002        \n",
      "Epoch 18: kld=0.00001   cross_entropy=0.00919   overall=0.00001        \n",
      "Epoch 19: kld=0.00001   cross_entropy=0.00920   overall=0.00001        \n",
      "Epoch 20: kld=0.00001   cross_entropy=0.00920   overall=0.00001       \n",
      "Epoch 21: kld=0.00001   cross_entropy=0.00921   overall=0.00001      \n",
      "Epoch 22: kld=0.00001   cross_entropy=0.00921   overall=0.00001        \n",
      "Epoch 23: kld=0.00001   cross_entropy=0.00922   overall=0.00001      \n",
      "Epoch 24: kld=0.00001   cross_entropy=0.00922   overall=0.00001        \n",
      "Epoch 25: kld=0.00001   cross_entropy=0.00923   overall=0.00001      \n",
      "Epoch 26: kld=0.00001   cross_entropy=0.00923   overall=0.00001      \n",
      "Epoch 27: kld=0.00000   cross_entropy=0.00923   overall=0.00000       \n",
      "Epoch 28: kld=0.00000   cross_entropy=0.00924   overall=0.00000       \n",
      "Epoch 29: kld=0.00000   cross_entropy=0.00924   overall=0.00000        \n",
      "Epoch 30: kld=0.00000   cross_entropy=0.00924   overall=0.00000        \n",
      "Epoch 31: kld=0.00000   cross_entropy=0.00924   overall=0.00000        \n",
      "Epoch 32: kld=0.00000   cross_entropy=0.00925   overall=0.00000      \n",
      "Epoch 33: kld=0.00000   cross_entropy=0.00925   overall=0.00000      \n",
      "Epoch 34: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 35: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 36: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 37: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 38: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 39: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 40: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 41: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 42: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 43: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 44: kld=0.00000   cross_entropy=0.00925   overall=0.00000       \n",
      "Epoch 45: kld=0.00000   cross_entropy=0.00925   overall=0.00000       \n",
      "Epoch 46: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 47: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 48: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n",
      "Epoch 49: kld=0.00000   cross_entropy=0.00925   overall=0.00000        \n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "num_classes = 4\n",
    "n_epochs = 50\n",
    "\n",
    "train_loader = get_loader(num_features=input_size, num_classes=num_classes)\n",
    "teacher = Teacher(input_size, num_classes, hidden_size=10)\n",
    "student = Student(input_size, num_classes)\n",
    "\n",
    "# Инициализируем политику функции потерь для дистилляции.\n",
    "# В этом примере используется стандартная политика, при которой\n",
    "# ученик учится сразу на распределение логитов учителя (KLD) и на мейнстрим задачу (CE).\n",
    "# Для кастомизации политики, например, для использования других функций потерь или\n",
    "# добавления адаптеров между аутпутами моделей, необходимо наследоваться от класса `AbstractDistillationPolicy`\n",
    "policy = BasicDistillationPolicy(temperature=0.5, alpha=1.0)\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cde3ed",
   "metadata": {},
   "source": [
    "### Student vs Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9da822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:\n",
      "tensor([[-0.1217,  0.1959, -0.2506, -0.5039],\n",
      "        [-0.1324,  0.0405, -0.1797, -0.4393],\n",
      "        [-0.0844,  0.0537, -0.1318, -0.4583],\n",
      "        [-0.1500,  0.1800, -0.2762, -0.5421],\n",
      "        [-0.1290,  0.1328, -0.2370, -0.5321]])\n",
      "Student output:\n",
      "tensor([[-0.0721,  0.2120, -0.1855, -0.4485],\n",
      "        [ 0.1190,  0.2183,  0.1295, -0.1383],\n",
      "        [ 0.2430,  0.3996,  0.1840, -0.1314],\n",
      "        [-0.0246,  0.3031, -0.1254, -0.3758],\n",
      "        [ 0.3515,  0.6541,  0.2204, -0.0737]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    random_input = torch.randn(5, input_size)\n",
    "    teacher_output = teacher(random_input)\n",
    "    student_output = student(random_input)\n",
    "    print('Teacher output:')\n",
    "    print(teacher_output)\n",
    "    print('Student output:')\n",
    "    print(student_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08b1140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08638\n"
     ]
    }
   ],
   "source": [
    "mse = nn.functional.mse_loss(student_output, teacher_output).item()\n",
    "print(f'MSE: {mse:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ac5a2",
   "metadata": {},
   "source": [
    "## Custom policy (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107031f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class SingleMSEDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def forward(self, teacher_output, student_output, batch, epoch) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        loss_mse = nn.functional.mse_loss(student_output, teacher_output)\n",
    "        loss_dict = {'mse': loss_mse.item()}\n",
    "        return loss_mse, loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1128389d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mse=0.00211                                                  \n",
      "Epoch 1: mse=0.00170                                                  \n",
      "Epoch 2: mse=0.00135                                                  \n",
      "Epoch 3: mse=0.00107                                                \n",
      "Epoch 4: mse=0.00083                                                  \n",
      "Epoch 5: mse=0.00064                                                  \n",
      "Epoch 6: mse=0.00049                                                  \n",
      "Epoch 7: mse=0.00037                                                  \n",
      "Epoch 8: mse=0.00028                                                  \n",
      "Epoch 9: mse=0.00020                                                  \n",
      "Epoch 10: mse=0.00015                                                  \n",
      "Epoch 11: mse=0.00011                                                  \n",
      "Epoch 12: mse=0.00008                                                  \n",
      "Epoch 13: mse=0.00006                                                  \n",
      "Epoch 14: mse=0.00004                                                  \n",
      "Epoch 15: mse=0.00003                                                  \n",
      "Epoch 16: mse=0.00002                                                  \n",
      "Epoch 17: mse=0.00002                                                  \n",
      "Epoch 18: mse=0.00001                                                  \n",
      "Epoch 19: mse=0.00001                                                  \n",
      "Epoch 20: mse=0.00001                                                  \n",
      "Epoch 21: mse=0.00001                                                  \n",
      "Epoch 22: mse=0.00001                                                  \n",
      "Epoch 23: mse=0.00001                                                  \n",
      "Epoch 24: mse=0.00001                                                  \n",
      "Epoch 25: mse=0.00001                                                  \n",
      "Epoch 26: mse=0.00001                                                  \n",
      "Epoch 27: mse=0.00001                                                  \n",
      "Epoch 28: mse=0.00001                                                  \n",
      "Epoch 29: mse=0.00001                                                  \n",
      "Epoch 30: mse=0.00001                                                  \n",
      "Epoch 31: mse=0.00001                                                  \n",
      "Epoch 32: mse=0.00001                                                  \n",
      "Epoch 33: mse=0.00001                                                  \n",
      "Epoch 34: mse=0.00001                                                  \n",
      "Epoch 35: mse=0.00001                                                \n",
      "Epoch 36: mse=0.00001                                                  \n",
      "Epoch 37: mse=0.00001                                                  \n",
      "Epoch 38: mse=0.00001                                                  \n",
      "Epoch 39: mse=0.00001                                                  \n",
      "Epoch 40: mse=0.00001                                                  \n",
      "Epoch 41: mse=0.00001                                                  \n",
      "Epoch 42: mse=0.00001                                                  \n",
      "Epoch 43: mse=0.00001                                                  \n",
      "Epoch 44: mse=0.00001                                                  \n",
      "Epoch 45: mse=0.00001                                                  \n",
      "Epoch 46: mse=0.00001                                                  \n",
      "Epoch 47: mse=0.00001                                                  \n",
      "Epoch 48: mse=0.00001                                                  \n",
      "Epoch 49: mse=0.00001                                                  \n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "num_classes = 4\n",
    "n_epochs = 50\n",
    "\n",
    "train_loader = get_loader(num_features=input_size, num_classes=num_classes)\n",
    "teacher = Teacher(input_size, num_classes, hidden_size=10)\n",
    "student = Student(input_size, num_classes)\n",
    "\n",
    "policy = SingleMSEDistillationPolicy()\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8a597",
   "metadata": {},
   "source": [
    "### Student vs Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b944dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:\n",
      "tensor([[ 0.2362,  0.2263,  0.1356, -0.0325],\n",
      "        [ 0.1388,  0.2534,  0.2083, -0.0543],\n",
      "        [ 0.2643,  0.1796,  0.0818,  0.0101],\n",
      "        [ 0.2930,  0.1302, -0.0004,  0.0206],\n",
      "        [ 0.2378,  0.1847,  0.1942, -0.0717]])\n",
      "Student output:\n",
      "tensor([[ 0.2172,  0.2265,  0.1470, -0.0575],\n",
      "        [ 0.2024,  0.2067,  0.1743, -0.0568],\n",
      "        [ 0.2816,  0.1567,  0.0250,  0.0484],\n",
      "        [ 0.3273,  0.1214,  0.0045,  0.0219],\n",
      "        [ 0.2050,  0.1613,  0.1797, -0.0603]])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    random_input = torch.randn(5, input_size)\n",
    "    teacher_output = teacher(random_input)\n",
    "    student_output = student(random_input)\n",
    "    print('Teacher output:')\n",
    "    print(teacher_output)\n",
    "    print('Student output:')\n",
    "    print(student_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f691c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00086\n"
     ]
    }
   ],
   "source": [
    "mse = nn.functional.mse_loss(student_output, teacher_output).item()\n",
    "print(f'MSE: {mse:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d91331",
   "metadata": {},
   "source": [
    "## Advanced policy\n",
    "**1. CE + MSE with scale decay**  \n",
    "**2. Layer adapter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e29d642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossDictT = Dict[str, float]\n",
    "\n",
    "\n",
    "class AdvancedDistillationPolicy(AbstractDistillationPolicy):\n",
    "    def __init__(self, n_epochs: int, adapter_mapping: Optional[Tuple[int, int]] = None):\n",
    "        super().__init__()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.adapter = nn.Identity() if adapter_mapping is None else nn.Linear(*adapter_mapping)\n",
    "    \n",
    "    def forward(self, teacher_output, student_output, batch, epoch) -> Tuple[torch.Tensor, LossDictT]:\n",
    "        alpha = (epoch + 1) / self.n_epochs\n",
    "        projected_teacher_logits = self.adapter(teacher_output)\n",
    "\n",
    "        loss_mse = nn.functional.mse_loss(student_output, projected_teacher_logits)\n",
    "        loss_ce = nn.functional.cross_entropy(student_output, batch[1])\n",
    "        overall = loss_mse * alpha + loss_ce * (1 - alpha)\n",
    "        scalars_dict = {\n",
    "            'mse': loss_mse.item(),\n",
    "            'cross_entropy': loss_ce.item(),\n",
    "            'overall': overall.item(),\n",
    "            'alpha': alpha,\n",
    "        }\n",
    "        return overall, scalars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bb4194f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: mse=0.00274   cross_entropy=0.01025   overall=0.01010   alpha=0.00013\n",
      "Epoch 1: mse=0.00254   cross_entropy=0.01009   overall=0.00979   alpha=0.00026\n",
      "Epoch 2: mse=0.00235   cross_entropy=0.00994   overall=0.00949   alpha=0.00038\n",
      "Epoch 3: mse=0.00217   cross_entropy=0.00981   overall=0.00919   alpha=0.00051\n",
      "Epoch 4: mse=0.00200   cross_entropy=0.00968   overall=0.00891   alpha=0.00064\n",
      "Epoch 5: mse=0.00184   cross_entropy=0.00957   overall=0.00864   alpha=0.00077\n",
      "Epoch 6: mse=0.00169   cross_entropy=0.00946   overall=0.00838   alpha=0.00090\n",
      "Epoch 7: mse=0.00155   cross_entropy=0.00937   overall=0.00812   alpha=0.00103\n",
      "Epoch 8: mse=0.00142   cross_entropy=0.00928   overall=0.00787   alpha=0.00115\n",
      "Epoch 9: mse=0.00129   cross_entropy=0.00921   overall=0.00763   alpha=0.00128\n",
      "Epoch 10: mse=0.00118   cross_entropy=0.00914   overall=0.00739   alpha=0.00141\n",
      "Epoch 11: mse=0.00106   cross_entropy=0.00908   overall=0.00716   alpha=0.00154\n",
      "Epoch 12: mse=0.00096   cross_entropy=0.00903   overall=0.00693   alpha=0.00167\n",
      "Epoch 13: mse=0.00086   cross_entropy=0.00899   overall=0.00671   alpha=0.00179\n",
      "Epoch 14: mse=0.00077   cross_entropy=0.00895   overall=0.00650   alpha=0.00192\n",
      "Epoch 15: mse=0.00069   cross_entropy=0.00892   overall=0.00628   alpha=0.00205\n",
      "Epoch 16: mse=0.00061   cross_entropy=0.00889   overall=0.00608   alpha=0.00218\n",
      "Epoch 17: mse=0.00054   cross_entropy=0.00887   overall=0.00587   alpha=0.00231\n",
      "Epoch 18: mse=0.00047   cross_entropy=0.00885   overall=0.00567   alpha=0.00244\n",
      "Epoch 19: mse=0.00041   cross_entropy=0.00884   overall=0.00547   alpha=0.00256\n",
      "Epoch 20: mse=0.00036   cross_entropy=0.00883   overall=0.00527   alpha=0.00269\n",
      "Epoch 21: mse=0.00031   cross_entropy=0.00883   overall=0.00508   alpha=0.00282\n",
      "Epoch 22: mse=0.00027   cross_entropy=0.00882   overall=0.00489   alpha=0.00295\n",
      "Epoch 23: mse=0.00023   cross_entropy=0.00882   overall=0.00470   alpha=0.00308\n",
      "Epoch 24: mse=0.00019   cross_entropy=0.00883   overall=0.00451   alpha=0.00321\n",
      "Epoch 25: mse=0.00017   cross_entropy=0.00883   overall=0.00432   alpha=0.00333\n",
      "Epoch 26: mse=0.00014   cross_entropy=0.00884   overall=0.00414   alpha=0.00346\n",
      "Epoch 27: mse=0.00012   cross_entropy=0.00884   overall=0.00396   alpha=0.00359\n",
      "Epoch 28: mse=0.00010   cross_entropy=0.00885   overall=0.00378   alpha=0.00372\n",
      "Epoch 29: mse=0.00008   cross_entropy=0.00886   overall=0.00360   alpha=0.00385\n",
      "Epoch 30: mse=0.00007   cross_entropy=0.00887   overall=0.00342   alpha=0.00397\n",
      "Epoch 31: mse=0.00006   cross_entropy=0.00889   overall=0.00324   alpha=0.00410\n",
      "Epoch 32: mse=0.00005   cross_entropy=0.00890   overall=0.00306   alpha=0.00423\n",
      "Epoch 33: mse=0.00004   cross_entropy=0.00891   overall=0.00288   alpha=0.00436\n",
      "Epoch 34: mse=0.00004   cross_entropy=0.00893   overall=0.00270   alpha=0.00449\n",
      "Epoch 35: mse=0.00003   cross_entropy=0.00894   overall=0.00252   alpha=0.00462\n",
      "Epoch 36: mse=0.00003   cross_entropy=0.00895   overall=0.00235   alpha=0.00474\n",
      "Epoch 37: mse=0.00002   cross_entropy=0.00897   overall=0.00217   alpha=0.00487\n",
      "Epoch 38: mse=0.00002   cross_entropy=0.00898   overall=0.00199   alpha=0.00500\n",
      "Epoch 39: mse=0.00002   cross_entropy=0.00899   overall=0.00181   alpha=0.00513\n",
      "Epoch 40: mse=0.00001   cross_entropy=0.00900   overall=0.00163   alpha=0.00526\n",
      "Epoch 41: mse=0.00001   cross_entropy=0.00902   overall=0.00145   alpha=0.00538\n",
      "Epoch 42: mse=0.00001   cross_entropy=0.00903   overall=0.00127   alpha=0.00551\n",
      "Epoch 43: mse=0.00001   cross_entropy=0.00904   overall=0.00109   alpha=0.00564\n",
      "Epoch 44: mse=0.00001   cross_entropy=0.00905   overall=0.00091   alpha=0.00577\n",
      "Epoch 45: mse=0.00001   cross_entropy=0.00906   overall=0.00073   alpha=0.00590\n",
      "Epoch 46: mse=0.00000   cross_entropy=0.00907   overall=0.00055   alpha=0.00603\n",
      "Epoch 47: mse=0.00000   cross_entropy=0.00909   overall=0.00037   alpha=0.00615\n",
      "Epoch 48: mse=0.00000   cross_entropy=0.00910   overall=0.00019   alpha=0.00628\n",
      "Epoch 49: mse=0.00000   cross_entropy=0.00910   overall=0.00000   alpha=0.00641\n"
     ]
    }
   ],
   "source": [
    "input_size = 32\n",
    "num_teacher_logits = 6\n",
    "num_student_logits = 4\n",
    "n_epochs = 50\n",
    "\n",
    "train_loader = get_loader(num_features=input_size, num_classes=num_classes)\n",
    "teacher = Teacher(input_size, num_teacher_logits, hidden_size=10)\n",
    "student = Student(input_size, num_student_logits)\n",
    "\n",
    "policy = AdvancedDistillationPolicy(n_epochs, adapter_mapping=(num_teacher_logits, num_student_logits))\n",
    "\n",
    "distiller = CustomDistiller(teacher, student, policy)\n",
    "distiller(train_loader, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a6ecc",
   "metadata": {},
   "source": [
    "### Student vs Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd970da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher output:\n",
      "tensor([[-0.1329,  0.1282, -0.1064,  0.2148,  0.0931,  0.2372],\n",
      "        [-0.1190,  0.1222, -0.0096,  0.1823,  0.0670,  0.2634],\n",
      "        [-0.0450,  0.0447, -0.0888,  0.1382,  0.0143,  0.1679],\n",
      "        [-0.1969,  0.2049, -0.0978,  0.1848,  0.0004, -0.0018],\n",
      "        [-0.0853, -0.0314, -0.0410,  0.1831, -0.0424,  0.2571]])\n",
      "Teacher after adapter output:\n",
      "tensor([[-0.0648, -0.2931,  0.3177, -0.1903],\n",
      "        [-0.0909, -0.2952,  0.2953, -0.1913],\n",
      "        [-0.0404, -0.2404,  0.2275, -0.2135],\n",
      "        [ 0.0391, -0.2174,  0.2448, -0.2471],\n",
      "        [-0.0678, -0.2120,  0.2082, -0.2116]])\n",
      "Student output:\n",
      "tensor([[-0.0602, -0.2900,  0.3141, -0.1946],\n",
      "        [-0.0661, -0.2699,  0.2632, -0.2029],\n",
      "        [-0.0341, -0.2654,  0.2787, -0.2143],\n",
      "        [ 0.0131, -0.2404,  0.2622, -0.2330],\n",
      "        [-0.0802, -0.2542,  0.2534, -0.2071]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    random_input = torch.randn(5, input_size)\n",
    "    teacher_output = teacher(random_input)\n",
    "    student_output = student(random_input)\n",
    "    print('Teacher output:')\n",
    "    print(teacher_output)\n",
    "    print('Teacher after adapter output:')\n",
    "    print(policy.adapter(teacher_output))\n",
    "    print('Student output:')\n",
    "    print(student_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d0ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00057\n"
     ]
    }
   ],
   "source": [
    "mse = nn.functional.mse_loss(student_output, policy.adapter(teacher_output)).item()\n",
    "print(f'MSE: {mse:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e70cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
